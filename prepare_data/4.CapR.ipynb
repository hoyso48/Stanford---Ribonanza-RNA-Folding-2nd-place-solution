{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2baa87-b95c-432c-9ae5-744577645871",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../datamount'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b424204-7770-4f57-804a-9663d8b81768",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd {DATA_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5635672d-74bb-45a3-a813-c6891b49bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see https://github.com/fukunagatsu/CapR for more details\n",
    "!git clone https://github.com/fukunagatsu/CapR.git\n",
    "!make -C ./CapR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "253807e5-fb60-4e36-9b3f-ba6182660862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4501/2169585939.py:6: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f455005d-e0b5-4237-81ff-0a9b4f5957b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./temp_fasta', exist_ok=True)\n",
    "os.makedirs('./CapR/CapR_predictions', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2298220-50a5-4229-85ca-044a5bb957d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fasta(filename, seq):\n",
    "    header = '>test\\n'\n",
    "    \n",
    "    with open(f'./temp_fasta/{filename}.fasta', 'w') as file:\n",
    "        file.write(header + seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0137c082-6782-4636-b05d-c085ab799ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capr(chunks):\n",
    "    for id, seq in tqdm(chunks.values):\n",
    "        capr_executable = './CapR/CapR'\n",
    "\n",
    "        save_fasta(id, seq)\n",
    "        \n",
    "        # If CapR requires command line arguments, add them here\n",
    "        args = [f'./temp_fasta/{id}.fasta', f'./CapR/CapR_predictions/{id}.txt', '512']\n",
    "        \n",
    "        # Combine the executable and the arguments in a single command\n",
    "        command = [capr_executable] + args\n",
    "        \n",
    "        # Run the command\n",
    "        process = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        \n",
    "        # Capture the output and errors\n",
    "        output = process.stdout.decode()\n",
    "        errors = process.stderr.decode()\n",
    "        # print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3706d911-d1f4-4ab1-bfea-75b0c94ebb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "def split_dataframe(df, chunk_size = 10000): \n",
    "    chunks = list()\n",
    "    num_chunks = len(df) // chunk_size + 1\n",
    "    for i in range(num_chunks):  \n",
    "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d179c82-ab3b-4bbb-b5d1-19b38e7704da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet('train_data_new.parquet')\n",
    "\n",
    "for dir in train_df['bpp_path'].apply(lambda x:x[:5]).unique():\n",
    "    os.makedirs('./CapR/CapR_predictions/' + dir, exist_ok=True)\n",
    "for dir in train_df['bpp_path'].apply(lambda x:x[:5]).unique():\n",
    "    os.makedirs('./temp_fasta/' + dir, exist_ok=True)    \n",
    "    \n",
    "result = Parallel(n_jobs=cpu_count())(\n",
    "    delayed(capr)(x)\n",
    "    for i,x in enumerate(split_dataframe(train_df[['bpp_path', 'sequence']], 10000))\n",
    ")\n",
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b50236-5b30-431e-b8ce-39b91e712f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_parquet('test_sequences_new.parquet')\n",
    "\n",
    "for dir in test_df['bpp_path'].apply(lambda x:x[:5]).unique():\n",
    "    os.makedirs('./CapR/CapR_predictions/' + dir, exist_ok=True)\n",
    "for dir in test_df['bpp_path'].apply(lambda x:x[:5]).unique():\n",
    "    os.makedirs('./temp_fasta/' + dir, exist_ok=True)    \n",
    "\n",
    "result = Parallel(n_jobs=cpu_count())(\n",
    "    delayed(capr)(x)\n",
    "    for i,x in enumerate(split_dataframe(test_df[['bpp_path', 'sequence']], 10000))\n",
    ")\n",
    "del test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89ad733-3098-4bcd-8b53-0caeb87281a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('./temp_fasta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
